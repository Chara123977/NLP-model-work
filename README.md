# NLP-model-work

# 1.基于 ERNIE 3.0 的Transformer微调分类模型，用于文本分类任务。
- 具体任务：CHIP-CTC（Chinese Medical Text Categorization）
- 输入数据：中文医疗文本（如电子病历、临床记录等）  
- 输出目标：为每条文本分配一个预定义的医学语义类别（如 “Disease”、“Diagnostic”、“Therapy or Surgery”、“Allergy Intolerance” 等）  

以下部分为日志

---
## 1.0
基础的模型，基于 ERNIE 3.0 模型进行微调，并完成文本分类任务。\
**于第二次训练之后出现明显过拟合问题** \
兴许是学习率过低以及训练次数过少?

## 1.1
提高训练轮数和容忍度\
采用更平滑的学习率衰减曲线参数\
**过拟合问题更加严重 该版模型已经不适用于此任务**\
或许该考虑回滚到一开始的模型状态

## 1.2
回滚到最开始的模型状态\
采用比初始值更低的学习率\
同时增加训练轮数到15轮\
**两轮训练对比下来 模型的拟合程度略有下降 但有所回暖**\
模型达到一个阶段性稳定点

## 1.3
把模型的混淆矩阵归一化处理\
**训练得到的图像和矩阵所表示出的质量明显比前一次高**\
或许模型已经达到一个 suitable 状态 可以投入使用了

---

# 2. 基于ERNIE 3.0 Medium 的深度学习模型, 用于序列标注任务
- 具体任务：从非结构化的中文医疗文本中，识别并分类出特定的医学实体片段
- 输入数据：中文医疗文本（如电子病历、临床记录等）  
- 输出目标：根据预定好的config标签 为文本中的每个 token 打上 BIO 标签

以下部分为日志

---

## 2.0
基础的模型，基于 ERNIE 3.0 Medium 模型进行微调，并完成序列标注任务。\
补完一个读取yaml参数文件的功能\
根据参数列表 尝试分别调整batchsize和learning rate\
调整max-seq-len和epoch不会是个好主意

## 2.1
分别对batchsize进行放大和缩小2/4倍\
得到的结果表明:
- batchsize增大时 模型的训练结果质量呈现出"部分提升 总体下降"的趋势 提升batchsize对模型的收敛速度有提升 但总体的性能下降
- batchsize缩小时 模型的训练结果质量呈现出"全面下降"的趋势 无论是速度还是性能都下降了

## 2.2
尝试对learning rate进行加大和减小1e-5\
得到的结果表明:
- learning rate增大时 模型的训练结果质量呈现出"总体上升"的趋势 收敛速度和预测性能都有所提升
- learning rate减小时 模型的训练结果质量呈现出"全面下降"的趋势 总体的收敛速度和性能都下降了

---

# 3. 基于预训练BERT的深度学习模型, 用于意图识别任务

- 具体任务：从非结构化的中文医疗文本中，识别并分类出特定的医学实体片段
- 输入数据：中文医疗文本（如电子病历、临床记录等）
- 输出目标：根据预定好的config标签 输出预定标签里最符合意图的那个

以下部分为日志

---

## 3.0
基础的模型，基于 BERT 模型进行微调，并完成意图识别任务。\
**发现使用的增强方式为同义替换**\
或许考虑替换成eda试试

## 3.1
尝试使用eda方法进行增强\
**eda策略的增强效果显著 但是曲线依然存在曲折点 不够平滑**
或许考虑使用CNN策略
